{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/JoannaBroniarek/DCGAN-for-MRI-images/blob/master/Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "LlwAthdRNGFe",
    "outputId": "f8d084ca-37be-467b-acda-080b9ac08f96"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AAOVx_T_NGEq"
   },
   "outputs": [],
   "source": [
    "# !ls '/gdrive/My Drive/NeuralNetworks/datasets/MICCAI_BraTS_2019_Data_Training/HGG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "vaM95rmnmE0m",
    "outputId": "b51d20d9-9162-4d19-a28a-6af513c0da63"
   },
   "outputs": [],
   "source": [
    "# !pip install -q SimpleITK dltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WROVmjRVbIwe"
   },
   "outputs": [],
   "source": [
    "# !pip install -q opencv-python imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tl-TVFnJG0p9"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tensorflow-gpu==2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jBGr4BEtmioD"
   },
   "outputs": [],
   "source": [
    "# %tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTN_osbANpLB"
   },
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from dltk.io.augmentation import *\n",
    "from dltk.io.preprocessing import *\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import PIL\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.utils import Progbar\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pXgfn0-Ll_EG",
    "outputId": "10fd80bf-f714-48f5-ac92-84b986cdd1ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PSu12ppk-10a",
    "outputId": "fe0287fb-64e5-4017-8bea-7a6157a4ea74"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "# tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3i4TXf2m2jm"
   },
   "outputs": [],
   "source": [
    "def load_img(file_path, subject_id):\n",
    "  x = []\n",
    "  \n",
    "  #  Construct a file path to read an image from.\n",
    "  t1_img = os.path.join(file_path, '{}/{}_t1.nii.gz'.format(subject_id, subject_id))\n",
    "\n",
    "  # Read the .nii image containing a brain volume with SimpleITK and get \n",
    "  # the numpy array:\n",
    "  sitk_t1 = sitk.ReadImage(t1_img)\n",
    "  t1 = sitk.GetArrayFromImage(sitk_t1)\n",
    "\n",
    "  # Select the slices from 50 to 125 among the whole 155 slices to omit initial/final slices, \n",
    "  # since they convey a negligible amount of useful information and could affect training\n",
    "  t1 = t1[50:125]\n",
    "  \n",
    "  # Resize images to 64 x 64 from 240 x 240\n",
    "  t1_new = np.zeros((t1.shape[0], 64, 64))\n",
    "  for i in range(t1.shape[0]):\n",
    "    t1_new[i] = cv2.resize(t1[i], dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "  # Normalise the image to zero mean/unit std dev:\n",
    "  t1 = whitening(t1_new)\n",
    "  \n",
    "  # Create a 4D Tensor with a dummy dimension for channels\n",
    "  t1 = t1[..., np.newaxis]\n",
    "  \n",
    "  return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VUczhqCkonkU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AK1BZf4Gon7E"
   },
   "source": [
    "**Write data into a TFRecords file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ro6pmLrJHhlN"
   },
   "outputs": [],
   "source": [
    "create_TF_RECORDS = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4heidXWHQjR-"
   },
   "outputs": [],
   "source": [
    "## copied from tensorflow site\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CclXEDwFokkt"
   },
   "outputs": [],
   "source": [
    "if create_TF_RECORDS:\n",
    "  # open the TFRecords file\n",
    "  # train_filename = '/gdrive/My Drive/NeuralNetworks/datasets/train.tfrecords' \n",
    "  train_filename = '../train.tfrecords'\n",
    "\n",
    "  writer = tf.io.TFRecordWriter(train_filename)\n",
    "\n",
    "  # Iterate through directories from the training dataset\n",
    "  dataset_path = '../data/'\n",
    "  # os.chdir(dataset_path)\n",
    "  counter = 1\n",
    "  for subject_id in tqdm(os.listdir(dataset_path)):\n",
    "\n",
    "    # Load the image\n",
    "    img = load_img(dataset_path, subject_id)\n",
    "\n",
    "    # Create a feature\n",
    "    feature = {'t1': _bytes_feature(tf.io.serialize_tensor(img, name=None))}\n",
    "    \n",
    "    # Create an example protocol buffer\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    \n",
    "    # Serialize to string and write on the file\n",
    "    writer.write(example.SerializeToString())\n",
    "    counter += 1\n",
    "\n",
    "  writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbl0lF3V0q-u"
   },
   "outputs": [],
   "source": [
    "def _decode(example_proto):\n",
    "  # Description of the features.\n",
    "  feature_description = {'t1': tf.io.FixedLenFeature([], tf.string)}\n",
    "  \n",
    "  # Parse the input `tf.Example` proto using the dictionary above.\n",
    "  features = tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "  img = tf.io.parse_tensor(features['t1'], out_type=tf.float32, name=None)\n",
    "  return img\n",
    "\n",
    "def parse_dataset(filename):\n",
    "  raw_dataset = tf.data.TFRecordDataset(filename)\n",
    "  return raw_dataset.map(_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jP9znPSFVeMt"
   },
   "outputs": [],
   "source": [
    "# plt.imshow(list(dataset.as_numpy_iterator())[0][0,5,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9QYD5ZOIW-y"
   },
   "source": [
    "#### **DCGAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ebgJlC1UTO0s"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Conv3D,\n",
    "                                     Dense,\n",
    "                                     Conv3DTranspose,\n",
    "                                     Reshape,\n",
    "                                     BatchNormalization,\n",
    "                                     Activation, \n",
    "                                     Flatten,\n",
    "                                     Dropout)\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qzbdXLCz8eyD"
   },
   "outputs": [],
   "source": [
    "def generator3d(img_shape=(75, 64, 64, 1),\n",
    "                noise_shape = (100, ),\n",
    "                kernel_size = (4, 4, 4),\n",
    "                strides = (1, 2, 2),\n",
    "                upsample_layers = 4,\n",
    "                starting_filters = 256):\n",
    "\n",
    "    filters = starting_filters\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "      Dense(np.int32(starting_filters * (img_shape[0])  * (img_shape[1] / (2 ** upsample_layers)) * (img_shape[2] / (2 ** upsample_layers))),\n",
    "            input_shape=noise_shape, use_bias=False))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Reshape(((img_shape[0]),\n",
    "                     np.int((img_shape[1] // (2 ** upsample_layers))),\n",
    "                     np.int((img_shape[2] // (2 ** upsample_layers))),\n",
    "                     starting_filters)))\n",
    "\n",
    "    ## 3 Hidden Convolution Layers\n",
    "    for l in range(upsample_layers-1):\n",
    "        filters = int(filters/2)\n",
    "        model.add(Conv3DTranspose(filters, kernel_size, strides,\n",
    "                                  padding='same', use_bias=False))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        ## 4th Convolution Layer\n",
    "        model.add(Conv3DTranspose(1, kernel_size, strides, \n",
    "                                padding='same', use_bias=False))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 307200)            30720000  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 307200)            1228800   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 307200)            0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 75, 4, 4, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose (Conv3DTran (None, 75, 8, 8, 128)     2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 75, 8, 8, 128)     512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 75, 8, 8, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_1 (Conv3DTr (None, 75, 16, 16, 64)    524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 75, 16, 16, 64)    256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 75, 16, 16, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_2 (Conv3DTr (None, 75, 32, 32, 32)    131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 75, 32, 32, 32)    128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 75, 32, 32, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_transpose_3 (Conv3DTr (None, 75, 64, 64, 1)     2048      \n",
      "=================================================================\n",
      "Total params: 34,704,256\n",
      "Trainable params: 34,089,408\n",
      "Non-trainable params: 614,848\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "generator3d().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ugk0flNL8e7U"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape (75, 64, 64, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d (Conv3D)              (None, 75, 32, 32, 64)    4160      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 75, 32, 32, 64)    0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 75, 32, 32, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 75, 16, 16, 128)   524416    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 75, 16, 16, 128)   0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 16, 16, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 75, 8, 8, 256)     2097408   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 75, 8, 8, 256)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 75, 8, 8, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 75, 4, 4, 512)     8389120   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 75, 4, 4, 512)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 75, 4, 4, 512)     0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 614400)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 614401    \n",
      "=================================================================\n",
      "Total params: 11,629,505\n",
      "Trainable params: 11,629,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def discriminator3d(input_shape=(75, 64, 64, 1),\n",
    "                    kernel_size = (4, 4, 4),\n",
    "                    strides = (1, 2, 2),\n",
    "                    upsample_layers = 4):\n",
    "    rate = 0.2\n",
    "    filters = input_shape[1]\n",
    "    print('input_shape', input_shape)\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv3D(strides=strides,\n",
    "                  kernel_size = kernel_size,\n",
    "                  filters = filters,\n",
    "                  input_shape=input_shape,\n",
    "                  padding='same'))\n",
    "    #   model.add(BatchNormalization())\n",
    "    model.add(Activation(\"elu\"))\n",
    "    model.add(Dropout(rate=rate))\n",
    "\n",
    "    for l in range(upsample_layers-1):\n",
    "        filters = int(filters*2)\n",
    "        model.add(Conv3D(strides=strides,\n",
    "                         kernel_size = kernel_size,\n",
    "                         filters = filters,\n",
    "                         padding='same'))\n",
    "    #     model.add(BatchNormalization())\n",
    "        model.add(Activation(\"elu\"))\n",
    "        model.add(Dropout(rate=rate))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "tf.keras.backend.clear_session()\n",
    "discriminator3d().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3vihq2lYnY9-"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KS3j_hngioL1"
   },
   "outputs": [],
   "source": [
    "@tf.function(autograph=True)\n",
    "def train_step(images):\n",
    "    batch_size = int(len(images))\n",
    "    noise = np.random.uniform(-1, 1, size=(batch_size, 100))\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
    "\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ejlNhV2kmTUL"
   },
   "outputs": [],
   "source": [
    "def train(dataset, num_training_samples, epochs, batch_size, lr, save_dir_path):\n",
    "  BUFFER_SIZE = 16\n",
    "  \n",
    "  checkpoint_dir = './training_checkpoints'\n",
    "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "  checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                  discriminator_optimizer=discriminator_optimizer,\n",
    "                                  generator=generator,\n",
    "                                  discriminator=discriminator)\n",
    "\n",
    "  dataset = dataset.shuffle(BUFFER_SIZE).batch(batch_size)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    print(\"\\nepoch {}/{}\".format(epoch+1,epochs))\n",
    "    pb_i = Progbar(target=num_training_samples, verbose=1)\n",
    "\n",
    "    for image_batch in dataset.as_numpy_iterator():\n",
    "      gen_loss, disc_loss = train_step(image_batch)\n",
    "      time.sleep(0.3)\n",
    "      pb_i.add(batch_size, values=[('gen_loss', gen_loss), ('disc_loss', disc_loss)])\n",
    "\n",
    "    # # Produce images for the GIF as we go\n",
    "    display.clear_output(wait=True)\n",
    "    test_noise = np.random.uniform(-1, 1, size=(1, 100))\n",
    "    gen_and_save_images(generator, epoch + 1, test_noise, save_dir_path, True)\n",
    "\n",
    "    # Save the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  # # Generate after the final epoch\n",
    "  display.clear_output(wait=True)\n",
    "  test_noise = np.random.uniform(-1, 1, size=(1, 100))\n",
    "  gen_and_save_images(generator, epoch + 1, test_noise, save_dir_path, True)\n",
    "\n",
    "\n",
    "def gen_and_save_images(model, epoch, test_noise, save_dir_path, show=False):\n",
    "  \n",
    "  preds = model(test_noise, training=False)\n",
    "  fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "  for ind, i in enumerate(range(20, 36)):\n",
    "    plt.subplot(4, 4, ind+1)\n",
    "    plt.imshow(preds[0][i,:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.savefig(\n",
    "      os.path.join(save_dir_path, 'img_epoch_{:04d}.png'.format(epoch)),\n",
    "      bbox_inches='tight')\n",
    "  if show:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qhf-h8tomTRT",
    "outputId": "c92aab1c-4a99-41f2-9162-1f2ce6a320ba"
   },
   "outputs": [],
   "source": [
    "## Load Dataset\n",
    "# train_filename = '/gdrive/My Drive/NeuralNetworks/datasets/train.tfrecords'\n",
    "train_filename = '../train.tfrecords'\n",
    "\n",
    "parsed_dataset = parse_dataset(train_filename)\n",
    "num_training_examples = sum(1 for _ in tf.data.TFRecordDataset(train_filename))\n",
    "print(num_training_examples)\n",
    "lr = 2e-4\n",
    "noise_dim = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 628
    },
    "colab_type": "code",
    "id": "q3uezf3m26Jc",
    "outputId": "c0da5c7c-433e-412f-dadc-a2ea9782a2ed"
   },
   "outputs": [],
   "source": [
    "## Train\n",
    "tf.keras.backend.clear_session()\n",
    "tf.keras.backend.set_floatx('float64')\n",
    "model_name = time.strftime('%Y-%m-%d_%H:%M:%S')\n",
    "if not os.path.exists(model_name):\n",
    "  os.mkdir(model_name)\n",
    "print(\"saving images in: {}\".format(model_name))\n",
    "\n",
    "generator=generator3d()\n",
    "print(generator.summary())\n",
    "discriminator=discriminator3d()\n",
    "print(discriminator.summary())\n",
    "generator_optimizer=tf.keras.optimizers.Adam(lr)\n",
    "discriminator_optimizer=tf.keras.optimizers.Adam(lr)\n",
    "\n",
    "\n",
    "train(dataset=parsed_dataset,\n",
    "      num_training_samples = num_training_examples, \n",
    "      epochs=5, \n",
    "      batch_size=32, \n",
    "      lr=lr,\n",
    "      save_dir_path = model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWurBDS1JpzB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhMe0G8xSnf7ff7Wx4TYgp",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "Neural_Networks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
